{"operators":[{"operatorID":"CSVFileScan-operator-d61df651-6f61-4242-a78b-c77d246e8bc3","operatorType":"CSVFileScan","operatorVersion":"c14deb143ea86b24f718654c929cfd618cbd4503","operatorProperties":{"fileEncoding":"UTF_8","customDelimiter":",","hasHeader":true,"fileName":"/Users/yicong-huang/Downloads/new-dataset_sentiment-ideology-merged.csv","limit":null,"offset":null},"inputPorts":[],"outputPorts":[{"portID":"output-0","displayName":"","allowMultiInputs":false,"isDynamicPort":false}],"showAdvanced":false,"isDisabled":false,"customDisplayName":"CSV File Scan","dynamicInputPorts":false,"dynamicOutputPorts":false},{"operatorID":"SimpleSink-operator-2a0d8d0a-959e-467e-8193-3e697424c39c","operatorType":"SimpleSink","operatorVersion":"f82d0affafcba93dada5e3d1e9f3367e5b53d037","operatorProperties":{},"inputPorts":[{"portID":"input-0","displayName":"","allowMultiInputs":false,"isDynamicPort":false}],"outputPorts":[],"showAdvanced":false,"isDisabled":false,"customDisplayName":"View Results","dynamicInputPorts":false,"dynamicOutputPorts":false},{"operatorID":"PythonUDFV2-operator-7eb7ba1f-80a2-4c05-bf7f-48d133cb10f9","operatorType":"PythonUDFV2","operatorVersion":"f82d0affafcba93dada5e3d1e9f3367e5b53d037","operatorProperties":{"code":"from pytexera import Tuple, TupleLike, UDFOperatorV2\nfrom typing import Iterator, Optional\nfrom overrides import overrides\n\nimport string\nfrom nltk.corpus import stopwords\nimport nltk\n\n\nclass DataCleaner(UDFOperatorV2):\n\n    def tokenize_lowercase(self, text):\n        tokens = nltk.word_tokenize(text)\n        stopwords_removed = [token.lower()\n                             for token in tokens if token.lower() not in self.stop_words]\n        return stopwords_removed\n\n    @staticmethod\n    def remove_nums_and_small_text(word_list):\n\n        no_nums = [word for word in word_list if word.isalpha()\n                   and len(word) >= 3]\n        return no_nums\n\n    def lemmatize_text(self, text):\n        lemmatized = []\n        for w in text:\n            lemmatized.append(self.lemmatizer.lemmatize(w))\n        return lemmatized\n\n    def clean(self, text: str) -> str:\n        tokenized = self.tokenize_lowercase(text)\n        small_words_removed = self.remove_nums_and_small_text(tokenized)\n        lemmatized = self.lemmatize_text(small_words_removed)\n        return ' '.join(lemmatized)\n\n    @overrides\n    def open(self):\n        self.stop_words = stopwords.words('english')\n        # add punctuation char's to stopwords list\n        # <-- contains !\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n        self.stop_words += list(string.punctuation)\n        # add integers\n        self.stop_words += ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n\n        self.lemmatizer = nltk.stem.WordNetLemmatizer()\n\n    @overrides\n    def process_tuple(self, tuple_: Tuple, port: int) -> Iterator[Optional[TupleLike]]:\n        for token in self.clean(tuple_['text']):\n            yield {\"token\" : token}\n        \n","retainInputColumns":false,"outputColumns":[{"attributeName":"token","attributeType":"string"}],"workers":1},"inputPorts":[{"portID":"input-0","displayName":"","allowMultiInputs":true,"isDynamicPort":false}],"outputPorts":[{"portID":"output-0","displayName":"","allowMultiInputs":false,"isDynamicPort":false}],"showAdvanced":false,"isDisabled":false,"customDisplayName":"NLTK Tokenizer","dynamicInputPorts":true,"dynamicOutputPorts":true},{"operatorID":"Aggregate-operator-91448724-f524-41eb-9bf5-feb8c194b7cc","operatorType":"Aggregate","operatorVersion":"73d2ca7026c93ca7898b3e9c0ce148b99bbf2726","operatorProperties":{"aggregations":[{"attribute":"token","result attribute":"count","aggFunction":"count"}],"groupByKeys":[]},"inputPorts":[{"portID":"input-0","displayName":"","allowMultiInputs":false,"isDynamicPort":false}],"outputPorts":[{"portID":"output-0","displayName":"","allowMultiInputs":false,"isDynamicPort":false}],"showAdvanced":false,"isDisabled":false,"customDisplayName":"Aggregate","dynamicInputPorts":false,"dynamicOutputPorts":false}],"operatorPositions":{"CSVFileScan-operator-d61df651-6f61-4242-a78b-c77d246e8bc3":{"x":146,"y":192},"SimpleSink-operator-2a0d8d0a-959e-467e-8193-3e697424c39c":{"x":668,"y":188},"PythonUDFV2-operator-7eb7ba1f-80a2-4c05-bf7f-48d133cb10f9":{"x":348,"y":192},"Aggregate-operator-91448724-f524-41eb-9bf5-feb8c194b7cc":{"x":520,"y":192}},"links":[{"linkID":"ab229ddc-7eda-4b4c-af04-83b638861481","source":{"operatorID":"CSVFileScan-operator-d61df651-6f61-4242-a78b-c77d246e8bc3","portID":"output-0"},"target":{"operatorID":"PythonUDFV2-operator-7eb7ba1f-80a2-4c05-bf7f-48d133cb10f9","portID":"input-0"}},{"linkID":"6a0bc30d-f751-4838-8c71-ea6a012234fe","source":{"operatorID":"PythonUDFV2-operator-7eb7ba1f-80a2-4c05-bf7f-48d133cb10f9","portID":"output-0"},"target":{"operatorID":"Aggregate-operator-91448724-f524-41eb-9bf5-feb8c194b7cc","portID":"input-0"}},{"linkID":"39d6aaad-f5b5-4418-b42d-b29c61f8b39a","source":{"operatorID":"Aggregate-operator-91448724-f524-41eb-9bf5-feb8c194b7cc","portID":"output-0"},"target":{"operatorID":"SimpleSink-operator-2a0d8d0a-959e-467e-8193-3e697424c39c","portID":"input-0"}}],"groups":[],"breakpoints":{},"commentBoxes":[]}