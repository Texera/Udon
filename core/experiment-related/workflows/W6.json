{"operators":[{"operatorID":"CSVFileScan-operator-d61df651-6f61-4242-a78b-c77d246e8bc3","operatorType":"CSVFileScan","operatorVersion":"c14deb143ea86b24f718654c929cfd618cbd4503","operatorProperties":{"fileEncoding":"UTF_8","customDelimiter":",","hasHeader":true,"fileName":"/Users/yicong-huang/Downloads/new-dataset_sentiment-ideology-merged.csv","limit":null,"offset":null},"inputPorts":[],"outputPorts":[{"portID":"output-0","displayName":"","allowMultiInputs":false,"isDynamicPort":false}],"showAdvanced":false,"isDisabled":false,"customDisplayName":"tweets","dynamicInputPorts":false,"dynamicOutputPorts":false},{"operatorID":"SimpleSink-operator-54b44d72-1944-4769-b0ed-84a3f3f45257","operatorType":"SimpleSink","operatorVersion":"f82d0affafcba93dada5e3d1e9f3367e5b53d037","operatorProperties":{},"inputPorts":[{"portID":"input-0","displayName":"","allowMultiInputs":false,"isDynamicPort":false}],"outputPorts":[],"showAdvanced":false,"isDisabled":false,"customDisplayName":"View Results","dynamicInputPorts":false,"dynamicOutputPorts":false},{"operatorID":"PythonUDFV2-operator-e6e9797a-fe9d-444a-bc43-1f28f42b9f03","operatorType":"PythonUDFV2","operatorVersion":"f82d0affafcba93dada5e3d1e9f3367e5b53d037","operatorProperties":{"code":"# Choose from the following templates:\n# \nfrom pytexera import *\n\nimport spacy\nfrom textblob import TextBlob\n\n# Load the small English model\nnlp = spacy.load(\"en_core_web_sm\")\n\n\nclass ProcessTupleOperator(UDFOperatorV2):\n    \n    @overrides\n    def process_tuple(self, tuple_: Tuple, port: int) -> Iterator[Optional[TupleLike]]:\n        tokens = nlp(tuple_['text'])  # Process the text using spaCy\n        pos_tags = [(token.text, token.pos_) for token in tokens]  # Create a list of (token, POS) pairs\n        for token, pos in pos_tags:\n            yield {\"token\": token, \"pos\": pos}\n    \n# \n# class ProcessBatchOperator(UDFBatchOperator):\n#     BATCH_SIZE = 10 # must be a positive integer\n# \n#     @overrides\n#     def process_batch(self, batch: Batch, port: int) -> Iterator[Optional[BatchLike]]:\n#         yield batch\n# \n# class ProcessTableOperator(UDFTableOperator):\n# \n#     @overrides\n#     def process_table(self, table: Table, port: int) -> Iterator[Optional[TableLike]]:\n#         yield table\n","retainInputColumns":false,"outputColumns":[{"attributeName":"token","attributeType":"string"},{"attributeName":"pos","attributeType":"string"}],"workers":1},"inputPorts":[{"portID":"input-0","displayName":"","allowMultiInputs":true,"isDynamicPort":false}],"outputPorts":[{"portID":"output-0","displayName":"","allowMultiInputs":false,"isDynamicPort":false}],"showAdvanced":false,"isDisabled":false,"customDisplayName":"spaCy Sentiment","dynamicInputPorts":true,"dynamicOutputPorts":true},{"operatorID":"PythonUDFV2-operator-21e8857b-8c1b-4cc0-9b88-03026d791e2a","operatorType":"PythonUDFV2","operatorVersion":"f82d0affafcba93dada5e3d1e9f3367e5b53d037","operatorProperties":{"code":"from pytexera import Tuple, TupleLike, UDFOperatorV2\nfrom typing import Iterator, Optional\nfrom overrides import overrides\n\nimport string\nfrom nltk.corpus import stopwords\nimport nltk\n\n\nclass DataCleaner(UDFOperatorV2):\n\n    def tokenize_lowercase(self, text):\n        tokens = nltk.word_tokenize(text)\n        stopwords_removed = [token.lower()\n                             for token in tokens if token.lower() not in self.stop_words]\n        return stopwords_removed\n\n    @staticmethod\n    def remove_nums_and_small_text(word_list):\n\n        no_nums = [word for word in word_list if word.isalpha()\n                   and len(word) >= 3]\n        return no_nums\n\n    def lemmatize_text(self, text):\n        lemmatized = []\n        for w in text:\n            lemmatized.append(self.lemmatizer.lemmatize(w))\n        return lemmatized\n\n    def clean(self, text: str) -> str:\n        tokenized = self.tokenize_lowercase(text)\n        small_words_removed = self.remove_nums_and_small_text(tokenized)\n        lemmatized = self.lemmatize_text(small_words_removed)\n        return ' '.join(lemmatized)\n\n    @overrides\n    def open(self):\n        self.stop_words = stopwords.words('english')\n        # add punctuation char's to stopwords list\n        # <-- contains !\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n        self.stop_words += list(string.punctuation)\n        # add integers\n        self.stop_words += ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n\n        self.lemmatizer = nltk.stem.WordNetLemmatizer()\n\n    @overrides\n    def process_tuple(self, tuple_: Tuple, port: int) -> Iterator[Optional[TupleLike]]:\n        tokens = self.clean(tuple_['text'])\n        tuple_['token_count'] = len(tokens)\n        yield tuple_\n        \n","retainInputColumns":true,"outputColumns":[{"attributeName":"token_count","attributeType":"integer"}],"workers":1},"inputPorts":[{"portID":"input-0","displayName":"","allowMultiInputs":true,"isDynamicPort":false}],"outputPorts":[{"portID":"output-0","displayName":"","allowMultiInputs":false,"isDynamicPort":false}],"showAdvanced":false,"isDisabled":false,"customDisplayName":"NLTK tokenizer","dynamicInputPorts":true,"dynamicOutputPorts":true},{"operatorID":"PythonUDFV2-operator-8c82afbd-3926-4ff5-873a-d5d1e84f64d9","operatorType":"PythonUDFV2","operatorVersion":"f82d0affafcba93dada5e3d1e9f3367e5b53d037","operatorProperties":{"code":"# Choose from the following templates:\n\nfrom pytexera import *\n\nclass ProcessTupleOperator(UDFOperatorV2):\n    \n    @overrides\n    def process_tuple(self, tuple_: Tuple, port: int) -> Iterator[Optional[TupleLike]]:\n        yield tuple_\n# \n# class ProcessBatchOperator(UDFBatchOperator):\n#     BATCH_SIZE = 10 # must be a positive integer\n# \n#     @overrides\n#     def process_batch(self, batch: Batch, port: int) -> Iterator[Optional[BatchLike]]:\n#         yield batch\n# \n# class ProcessTableOperator(UDFTableOperator):\n# \n#     @overrides\n#     def process_table(self, table: Table, port: int) -> Iterator[Optional[TableLike]]:\n#         yield table\n","retainInputColumns":true,"outputColumns":[],"workers":1},"inputPorts":[{"portID":"input-0","displayName":"","allowMultiInputs":true,"isDynamicPort":false}],"outputPorts":[{"portID":"output-0","displayName":"","allowMultiInputs":false,"isDynamicPort":false}],"showAdvanced":false,"isDisabled":false,"customDisplayName":"dummy","dynamicInputPorts":true,"dynamicOutputPorts":true}],"operatorPositions":{"CSVFileScan-operator-d61df651-6f61-4242-a78b-c77d246e8bc3":{"x":-38,"y":74},"SimpleSink-operator-54b44d72-1944-4769-b0ed-84a3f3f45257":{"x":700,"y":80},"PythonUDFV2-operator-e6e9797a-fe9d-444a-bc43-1f28f42b9f03":{"x":560,"y":80},"PythonUDFV2-operator-21e8857b-8c1b-4cc0-9b88-03026d791e2a":{"x":145,"y":75.01040649414062},"PythonUDFV2-operator-8c82afbd-3926-4ff5-873a-d5d1e84f64d9":{"x":328,"y":77.96614837646484}},"links":[{"linkID":"link-aaa066b4-90a1-40ec-97bf-cbb6b72010c4","source":{"operatorID":"PythonUDFV2-operator-e6e9797a-fe9d-444a-bc43-1f28f42b9f03","portID":"output-0"},"target":{"operatorID":"SimpleSink-operator-54b44d72-1944-4769-b0ed-84a3f3f45257","portID":"input-0"}},{"linkID":"link-f7b58259-9bf9-4460-9d9b-e5091d003a89","source":{"operatorID":"CSVFileScan-operator-d61df651-6f61-4242-a78b-c77d246e8bc3","portID":"output-0"},"target":{"operatorID":"PythonUDFV2-operator-21e8857b-8c1b-4cc0-9b88-03026d791e2a","portID":"input-0"}},{"linkID":"link-6e0f63ff-bea5-4526-911d-4bd3c300c9d1","source":{"operatorID":"PythonUDFV2-operator-21e8857b-8c1b-4cc0-9b88-03026d791e2a","portID":"output-0"},"target":{"operatorID":"PythonUDFV2-operator-8c82afbd-3926-4ff5-873a-d5d1e84f64d9","portID":"input-0"}},{"linkID":"link-c3dc1ea0-3662-4f35-aab1-17f526f138c1","source":{"operatorID":"PythonUDFV2-operator-8c82afbd-3926-4ff5-873a-d5d1e84f64d9","portID":"output-0"},"target":{"operatorID":"PythonUDFV2-operator-e6e9797a-fe9d-444a-bc43-1f28f42b9f03","portID":"input-0"}}],"groups":[],"breakpoints":{},"commentBoxes":[]}